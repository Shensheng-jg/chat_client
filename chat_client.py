import os
import re
import io
import json
import base64
from typing import List, Optional
import gradio as gr
from openai import OpenAI
from dotenv import load_dotenv
from PIL import Image

load_dotenv()

# ===== é»˜è®¤é…ç½®ï¼ˆå¯ç”¨ .env è¦†ç›–ï¼‰=====
DEFAULT_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.openai-proxy.org/v1")
DEFAULT_API_KEY  = os.getenv("LLM_API_KEY", "")
DEFAULT_MODEL    = os.getenv("LLM_MODEL", "gemini-1.5-pro")
DEFAULT_SYSTEM   = os.getenv("LLM_SYSTEM_PROMPT", "You are a helpful AI assistant.")
DEFAULT_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))

# ===== æç¤ºè¯æ¨¡æ¿ï¼ˆå¯æŒä¹…åŒ–åˆ° templates.jsonï¼‰=====
TEMPLATES = {
    "ç³»ç»Ÿ-ä¸¥è°¨ä¸­æ–‡å›ç­”": {
        "scope": "system",
        "text": (
            "ä½ æ˜¯ä¸“ä¸šåŠ©ç†ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡ï¼Œç»™å‡ºç®€æ´ã€ç»“æ„åŒ–å›ç­”ã€‚"
            "å¿…è¦æ—¶åˆ—æ¸…å•ï¼Œæ¶‰åŠä»£ç éœ€è‡ªæ£€å¯è¿è¡Œã€‚"
        )
    },
    "ä»£ç è®²è§£": {
        "scope": "user",
        "text": (
            "è¯·é€æ­¥è§£é‡Šè¿™æ®µä»£ç çš„åŠŸèƒ½ã€å¤æ‚åº¦ä¸æ½œåœ¨ bugï¼Œå¹¶ç»™å‡ºæ›´ä¼˜å†™æ³•ï¼š\n"
            "```{lang}\n{code}\n```"
        )
    },
    "å†™ä½œ-æ”¹å†™æ¶¦è‰²": {
        "scope": "user",
        "text": (
            "æŠŠä¸‹é¢æ–‡æœ¬æ”¹å†™ä¸ºæ›´{tone}çš„é£æ ¼ï¼Œä¿æŒå«ä¹‰ä¸å˜ï¼Œå¹¶è¾“å‡ºä¸‰ä¸ªç‰ˆæœ¬ï¼š\n{content}"
        )
    },
}
_TPL_PATH = "templates.json"

def _load_templates():
    global TEMPLATES
    if os.path.exists(_TPL_PATH):
        try:
            with open(_TPL_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, dict):
                    TEMPLATES.update(data)
        except Exception:
            pass

def _save_templates():
    try:
        with open(_TPL_PATH, "w", encoding="utf-8") as f:
            json.dump(TEMPLATES, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

_load_templates()

# ===== Base URL è§„èŒƒåŒ– / å®¢æˆ·ç«¯å·¥å‚ =====
def _normalize_base_url(url: str) -> str:
    """è‹¥æœ«å°¾ä¸æ˜¯ /v{æ•°å­—} æˆ– /v{æ•°å­—}/ ï¼Œåˆ™è‡ªåŠ¨è¡¥ /v1ã€‚"""
    if not url:
        return url
    u = url.rstrip("/")
    # å·²ç»æ˜¯ /v1ã€/v1betaã€/v2 ç­‰ç‰ˆæœ¬è·¯å¾„å°±ä¸å†è¿½åŠ 
    if re.search(r"/v\d+([a-zA-Z].*)?$", u):
        return u
    return u + "/v1"

def _make_client(api_key: str, base_url: str) -> OpenAI:
    if not api_key:
        raise ValueError("è¯·å¡«å†™ API Key")
    if not base_url:
        raise ValueError("è¯·å¡«å†™ Base URL")
    nb = _normalize_base_url(base_url)
    return OpenAI(api_key=api_key, base_url=nb)

# ===== Chatbot å†å²ï¼šlist[[user, assistant], ...] =====
def _ensure_pairs(hist):
    """æŠŠå†å²ä¿®æ­£ä¸º list[[user, assistant], ...]ï¼Œå¹¶æŠŠ None/éå­—ç¬¦ä¸²è½¬ä¸ºå­—ç¬¦ä¸²ã€‚"""
    fixed = []
    for m in hist or []:
        if isinstance(m, tuple):
            m = list(m)
        if not (isinstance(m, list) and len(m) == 2):
            continue
        u, a = m
        u = "" if u is None else str(u)
        a = "" if a is None else str(a)
        fixed.append([u, a])
    return fixed

# ===== å›¾ç‰‡å¤„ç†ï¼ˆå‹ç¼©ä¸º data URL ä»¥ä¾¿ image_url ä¼ å…¥ï¼‰=====
def _compress_to_data_url(img: Image.Image, fmt="JPEG", max_side=1600, quality=85) -> str:
    # ç¼©æ”¾åˆ°è¾ƒå°è¾¹ç•Œï¼Œé™ä½ token / è´¹ç”¨
    w, h = img.size
    if max(w, h) > max_side:
        if w >= h:
            nw, nh = max_side, int(h * (max_side / w))
        else:
            nh, nw = max_side, int(w * (max_side / h))
        img = img.resize((nw, nh))
    if img.mode in ("RGBA", "P"):
        img = img.convert("RGB")
    buf = io.BytesIO()
    img.save(buf, fmt, quality=quality, optimize=True)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    mime = "image/jpeg" if fmt.upper() == "JPEG" else "image/png"
    return f"data:{mime};base64,{b64}"

def _filepath_to_data_url(path: str) -> Optional[str]:
    try:
        with Image.open(path) as im:
            return _compress_to_data_url(im, fmt="JPEG")
    except Exception:
        return None

# ===== messages ç»„è£… =====
def _messages_for_chat(system_prompt, history_pairs, user_parts):
    msgs = []
    if system_prompt:
        msgs.append({"role": "system", "content": system_prompt})
    for u, a in history_pairs:
        if u:
            msgs.append({"role": "user", "content": u})
        if a:
            msgs.append({"role": "assistant", "content": a})
    msgs.append({"role": "user", "content": user_parts})
    return msgs

def _msgs_to_text_for_fallback(msgs):
    """responses å…œåº•æ—¶ï¼Œä»…ä¿æ–‡æœ¬å†…å®¹"""
    lines = []
    for m in msgs:
        role = m.get("role", "user")
        content = m.get("content", "")
        if isinstance(content, list):
            texts = []
            for part in content:
                if part.get("type") in ("text", "input_text"):
                    texts.append(part.get("text") or part.get("content") or "")
            content = "\n".join(texts)
        lines.append(f"{role.upper()}: {content}")
    return "\n".join(lines)

# ===== æç¤ºè¯æ¨¡æ¿ï¼šå˜é‡è§£æä¸æ¸²æŸ“ =====
def _parse_kv_lines(kv_text: str) -> dict:
    """
    key=value æ¯è¡Œä¸€å¯¹ï¼Œå…è®¸ value å« '='ï¼ˆä»…åˆ†å‰²ç¬¬ä¸€ä¸ª '=').
    ä¾‹ï¼š
      lang=python
      tone=å­¦æœ¯
      code=print('hello')
    """
    vars = {}
    if not kv_text:
        return vars
    for line in kv_text.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if "=" in line:
            k, v = line.split("=", 1)
            vars[k.strip()] = v.strip()
    return vars

def _render_template(name: str, kv_text: str) -> str:
    """ç”¨ {å˜é‡} è¿›è¡Œå®‰å…¨æ›¿æ¢ï¼›ç¼ºå¤±å˜é‡ä¼šåŸæ ·ä¿ç•™ã€‚"""
    tpl = TEMPLATES.get(name, {}).get("text", "")
    class _SafeDict(dict):
        def __missing__(self, key):
            return "{" + key + "}"
    return tpl.format_map(_SafeDict(_parse_kv_lines(kv_text)))

# ===== æ„å»ºæœ¬è½®ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰=====
def _build_user_content(user_text: str,
                        file_paths: Optional[List[str]],
                        url_text: Optional[str]):
    """
    è¿”å› messages ä¸­ user çš„ contentï¼ˆlist[parts]ï¼‰ï¼Œä»¥åŠç”¨äºå¯è§†åŒ–çš„å ä½è¯´æ˜ã€‚
    """
    parts = []
    if user_text:
        parts.append({"type": "text", "text": user_text})

    # URLï¼ˆå¤šè¡Œï¼Œæ¯è¡Œä¸€ä¸ªï¼‰
    url_list = []
    if url_text:
        for line in url_text.splitlines():
            u = line.strip()
            if u:
                url_list.append(u)

    for u in url_list:
        parts.append({"type": "image_url", "image_url": {"url": u, "detail": "high"}})

    # æœ¬åœ°æ–‡ä»¶ â†’ data URL
    count_files = 0
    if file_paths:
        for p in file_paths:
            data_url = _filepath_to_data_url(p)
            if data_url:
                parts.append({"type": "image_url", "image_url": {"url": data_url, "detail": "high"}})
                count_files += 1

    # å¯è§†åŒ–å ä½æ–‡æ¡ˆï¼ˆä¸æŠŠ base64 å¡è¿›èŠå¤©çª—å£ï¼Œé¿å… UI è¿‡å¤§ï¼‰
    attach_note = ""
    total_imgs = len(url_list) + count_files
    if total_imgs > 0:
        attach_note = f"\n\nğŸ–¼ï¸ å·²é™„åŠ  {total_imgs} å¼ å›¾ç‰‡ï¼ˆ{count_files} æœ¬åœ° / {len(url_list)} URLï¼‰"

    visible_user_text = (user_text or "").strip()
    visible_user_text = visible_user_text + attach_note

    return parts, visible_user_text

# ===== æ ¸å¿ƒï¼šæµå¼ + å…œåº• =====
def stream_chat(api_key, base_url, model, system_prompt, temperature,
                history, user_msg, image_files, image_urls):
    """
    ç”Ÿæˆå™¨ï¼šæ¯æ¬¡ yield è¿”å› (chat_history, state) ä¸¤ä¸ªè¾“å‡ºã€‚
    history: list[[user, assistant], ...]
    image_files: list[str] (gr.Files è¿”å›æ–‡ä»¶è·¯å¾„åˆ—è¡¨æˆ–å¸¦ name/path çš„å¯¹è±¡)
    image_urls: str (å¤šè¡Œï¼Œæ¯è¡Œä¸€ä¸ª URL)
    """
    history = _ensure_pairs(history)
    client = _make_client(api_key, base_url)

    # æ”¶é›†æ–‡ä»¶è·¯å¾„
    file_paths = []
    if image_files:
        for f in image_files:
            if isinstance(f, str):
                file_paths.append(f)
            else:
                path = getattr(f, "name", None) or getattr(f, "path", None)
                if path:
                    file_paths.append(path)

    # æ„é€ æœ¬è½®ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
    user_parts, visible_user = _build_user_content(user_msg, file_paths, image_urls)
    if len(user_parts) == 0:
        history.append(["ï¼ˆç©ºæ¶ˆæ¯ï¼‰", "âš ï¸ è¯·è¾“å…¥æ–‡æœ¬æˆ–é™„åŠ å›¾ç‰‡/URL"])
        yield _ensure_pairs(history), _ensure_pairs(history)
        return

    # ç»„è£… messages
    messages = _messages_for_chat(system_prompt, history, user_parts)

    # å…ˆåœ¨ UI å ä½
    history.append([visible_user, ""])
    yield _ensure_pairs(history), _ensure_pairs(history)

    # é¦–é€‰ï¼šchat.completions æµå¼
    partial = ""
    try:
        stream = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            stream=True,
        )
        for chunk in stream:
            delta = getattr(chunk.choices[0], "delta", None)
            if delta and getattr(delta, "content", None):
                partial += delta.content
                history[-1][1] = partial
                yield _ensure_pairs(history), _ensure_pairs(history)
        return
    except Exception as e1:
        err1 = f"{type(e1).__name__}: {e1}"

    # å…œåº•ï¼šresponsesï¼ˆå¤šæ•°ä»£ç†å¯¹å›¾ç‰‡ä¸ä¸€å®šå…¼å®¹ï¼Œæ­¤å¤„ä»…ä¿æ–‡æœ¬ï¼‰
    try:
        r = client.responses.create(
            model=model,
            input=_msgs_to_text_for_fallback(messages),
            temperature=temperature,
        )
        reply = getattr(r, "output_text", None) or str(r)
        history[-1][1] = reply
        yield _ensure_pairs(history), _ensure_pairs(history)
    except Exception as e2:
        history[-1][1] = f"âš ï¸ è¯·æ±‚å‡ºé”™ï¼ˆå·²å°è¯• chat.completions ä¸ responsesï¼‰ï¼š\n1) {err1}\n2) {type(e2).__name__}: {e2}"
        yield _ensure_pairs(history), _ensure_pairs(history)

# ===== æ¸…ç©º =====
def clear_all():
    empty = []
    return empty, empty

# ===== æ¨¡æ¿æŒ‰é’®å›è°ƒ =====
def _apply_to_system(name, kv, cur_text):
    if not name:
        return gr.update(value=cur_text)
    return gr.update(value=_render_template(name, kv))

def _apply_to_msg(name, kv, cur_text):
    if not name:
        return gr.update(value=cur_text)
    new_text = (cur_text or "").rstrip()
    rendered = _render_template(name, kv)
    if new_text:
        new_text = new_text + "\n\n" + rendered
    else:
        new_text = rendered
    return gr.update(value=new_text)

def _save_from_text(name, scope, text):
    if not name or not text:
        return gr.update(choices=sorted(TEMPLATES.keys()))
    TEMPLATES[name] = {"scope": scope, "text": text}
    _save_templates()
    return gr.update(choices=sorted(TEMPLATES.keys()), value=name)

def _delete_tpl(name):
    if name in TEMPLATES:
        del TEMPLATES[name]
        _save_templates()
    # åŒæ—¶æ›´æ–°ä¸¤ä¸ªä¸‹æ‹‰æ¡†ï¼ˆè‹¥ä½ ç”¨äº†ä¸¤ä¸ªï¼‰
    upd = gr.update(choices=sorted(TEMPLATES.keys()), value=None)
    return upd, upd

def _rename_tpl(old_name, new_name):
    if old_name and new_name and old_name in TEMPLATES:
        TEMPLATES[new_name] = TEMPLATES.pop(old_name)
        _save_templates()
    upd = gr.update(choices=sorted(TEMPLATES.keys()), value=new_name or old_name)
    return upd, upd

# ===== Gradio UI =====
with gr.Blocks(title="LLM Client (OpenAI-Compatible)", theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ§  LLM Client Â· OpenAI-Compatibleï¼ˆæ–‡æœ¬ + å›¾ç‰‡ + æ¨¡æ¿ï¼‰")

    with gr.Row():
        base_url = gr.Textbox(label="Base URL", value=DEFAULT_BASE_URL, placeholder="å¦‚ï¼šhttps://api.openai-proxy.org/v1")
        api_key  = gr.Textbox(label="API Key", value=DEFAULT_API_KEY, type="password", placeholder="ä½ çš„å¯†é’¥")

    with gr.Row():
        model = gr.Textbox(label="Model", value=DEFAULT_MODEL, placeholder="å¦‚ï¼šgemini-1.5-pro / gpt-4o-mini")
        temperature = gr.Slider(0.0, 1.5, value=DEFAULT_TEMPERATURE, step=0.1, label="Temperature")

    system_prompt = gr.Textbox(label="System Promptï¼ˆå¯é€‰ï¼‰", value=DEFAULT_SYSTEM, lines=2)

    # â€”â€” æç¤ºè¯æ¨¡æ¿åŒº â€”â€”
    with gr.Accordion("æç¤ºè¯æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰", open=False):
        tpl_name = gr.Dropdown(
            label="é€‰æ‹©æ¨¡æ¿",
            choices=sorted(TEMPLATES.keys()),
            allow_custom_value=False
        )
        tpl_vars = gr.Textbox(
            label="æ¨¡æ¿å˜é‡ï¼ˆkey=valueï¼Œæ¯è¡Œä¸€å¯¹ï¼‰",
            placeholder="lang=python\ntone=å­¦æœ¯\ncode=print('hello')\ncontent=å¾…æ”¹å†™æ–‡æœ¬...",
            lines=5
        )
        with gr.Row():
            btn_apply_to_system = gr.Button("åº”ç”¨åˆ° System Prompt")
            btn_apply_to_msg    = gr.Button("åº”ç”¨åˆ° Message")

        with gr.Row():
            tpl_new_name = gr.Textbox(label="ä¿å­˜ä¸ºæ¨¡æ¿çš„åç§°")
            tpl_scope = gr.Radio(["system", "user"], value="user", label="æ¨¡æ¿ç±»å‹")
            btn_save_tpl_from_msg = gr.Button("ä» Message ä¿å­˜")
            btn_save_tpl_from_sys = gr.Button("ä» System ä¿å­˜")

        with gr.Row():
            tpl_sel_manage = gr.Dropdown(label="é€‰æ‹©æ¨¡æ¿ï¼ˆåˆ é™¤/é‡å‘½åï¼‰",
                                        choices=sorted(TEMPLATES.keys()))
            tpl_new_name2 = gr.Textbox(label="æ–°åç§°ï¼ˆç”¨äºé‡å‘½åï¼‰")

        with gr.Row():
            btn_delete_tpl = gr.Button("åˆ é™¤æ‰€é€‰æ¨¡æ¿", variant="stop")
            btn_rename_tpl = gr.Button("é‡å‘½åæ¨¡æ¿")

        # ç»‘å®šäº‹ä»¶ï¼ˆåŒæ—¶æ›´æ–° ç®¡ç†ä¸‹æ‹‰æ¡† ä¸ é€‰æ‹©æ¨¡æ¿ä¸‹æ‹‰æ¡†ï¼‰
        btn_delete_tpl.click(_delete_tpl, inputs=[tpl_sel_manage], outputs=[tpl_name, tpl_sel_manage])
        btn_rename_tpl.click(_rename_tpl, inputs=[tpl_sel_manage, tpl_new_name2], outputs=[tpl_name, tpl_sel_manage])

    # â€”â€” å›¾ç‰‡è¾“å…¥ï¼ˆæœ¬åœ°ä¸ URLï¼‰ â€”â€”
    with gr.Accordion("é™„åŠ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰", open=False):
        image_files = gr.Files(label="ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯å¤šé€‰ï¼‰", file_types=["image"], file_count="multiple")
        image_urls  = gr.Textbox(label="å›¾ç‰‡ URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¯å¤šè¡Œï¼‰", lines=3, placeholder="https://.../a.jpg\nhttps://.../b.png")

    chat = gr.Chatbot(height=480, avatar_images=(None, None))
    msg = gr.Textbox(placeholder="è¾“å…¥æ–‡æœ¬ï¼Œå¯é€‰é™„åŠ å›¾ç‰‡æˆ–å›¾ç‰‡URL", label="Message")
    with gr.Row():
        send_btn = gr.Button("å‘é€", variant="primary")
        clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")

    state = gr.State([])

    # å‘é€ / å›è½¦æäº¤
    inputs = [api_key, base_url, model, system_prompt, temperature, state, msg, image_files, image_urls]
    outputs = [chat, state]
    send_btn.click(stream_chat, inputs=inputs, outputs=outputs)
    msg.submit(stream_chat, inputs=inputs, outputs=outputs)

    # æ¸…ç©º
    clear_btn.click(clear_all, None, outputs)

    # æ¨¡æ¿æŒ‰é’®ç»‘å®š
    btn_apply_to_system.click(
        _apply_to_system,
        inputs=[tpl_name, tpl_vars, system_prompt],
        outputs=[system_prompt]
    )
    btn_apply_to_msg.click(
        _apply_to_msg,
        inputs=[tpl_name, tpl_vars, msg],
        outputs=[msg]
    )
    btn_save_tpl_from_msg.click(
        _save_from_text,
        inputs=[tpl_new_name, tpl_scope, msg],
        outputs=[tpl_name]
    )
    btn_save_tpl_from_sys.click(
        _save_from_text,
        inputs=[tpl_new_name, tpl_scope, system_prompt],
        outputs=[tpl_name]
    )

if __name__ == "__main__":
    demo.queue().launch(server_name="0.0.0.0", server_port=7860, show_error=True)
